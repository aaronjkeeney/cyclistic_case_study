---
author: "Aaron"
date: "2023-06-20"
title: "Google Certificate in Data Analytics"
knit: (function(input, encoding) {rmarkdown::render(input, output_file = 'README')})
output: github_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Capstone Project #1

### Introduction
This is the first of several projects for practicing and showcasing what I have learned throughout this course. In this case study, my main focus is to develop a solid R Markdown document for ease of creating a report that is easily followed by colleagues and stakeholders.

#### Notes
These [data](https://divvy-tripdata.s3.amazonaws.com/index.html) are provided under [this license](https://ride.divvybikes.com/data-license-agreement). Since the dataset(s) are extremely large, I intend to compile and clean them in BigQuery and/or R. If there ends up being a smaller dataset, I might switch to a spreadsheet, unless I have already laid the necessary infrastructure in R.

Thank you to HanOostdijk for giving some [advice](https://community.rstudio.com/t/rmarkdow-how-can-i-create-a-pdf-file-with-different-name-from-rmd/67879) with knitting to git.

## Business Goals (Ask)
Director of Marketing, Lily Moreno has asked for analysis of Cyclistic's internal data, with the overarching goal of converting casual users into annual subscribers. She has asked three specific questions:

* How do annual members and casual riders use Cyclistic bikes differently?

* Why would casual riders buy Cyclistic annual memberships?

* How can Cyclistic use digital media to influence casual riders to become members?

For this report, we will focus on the first question and analyze the differences in use patterns by casual riders and annual members.

## Data Preparation (Prepare/Process)
Ride data from June 2022 to May 2023 were retrieved from Cyclistic's internal database. (Note: the data are actually made available by Motivate International Inc. via the previous link.)

The data files contain tables with about 200,000 to 1,000,000 rows, so Spreadsheets will be too bulky for the initial cleaning and preparation.

#### These are the necessary packages for this analysis.
```{r}
library(tidyverse)
library(readr)
library(lubridate)
library(ggplot2)
library(knitr)
getwd()
setwd("~/Desktop/Coding Projects/Capstone_Cyclistic_Raw_Data/Cyclistic_csv_files")
```

#### Importing the necessary data.
##### Note: changed September from "trippublicdata" to "tripdata" for consistency.
```{r}
setwd("~/Desktop/Coding Projects/Capstone_Cyclistic_Raw_Data/Cyclistic_csv_files")
Jun_2022 <- read_csv("202206-divvy-tripdata.csv")
Jul_2022 <- read_csv("202207-divvy-tripdata.csv")
Aug_2022 <- read_csv("202208-divvy-tripdata.csv")
Sep_2022 <- read_csv("202209-divvy-tripdata.csv")
Oct_2022 <- read_csv("202210-divvy-tripdata.csv")
Nov_2022 <- read_csv("202211-divvy-tripdata.csv")
Dec_2022 <- read_csv("202212-divvy-tripdata.csv")
Jan_2023 <- read_csv("202301-divvy-tripdata.csv")
Feb_2023 <- read_csv("202302-divvy-tripdata.csv")
Mar_2023 <- read_csv("202303-divvy-tripdata.csv")
Apr_2023 <- read_csv("202304-divvy-tripdata.csv")
May_2023 <- read_csv("202305-divvy-tripdata.csv")
```

#### After using colnames() and str() to ensure matching datasets, 
#### the above datasets were merged.
```{r}
all_trips <- rbind(Jun_2022, Jul_2022, Aug_2022, Sep_2022, Oct_2022, 
                       Nov_2022, Dec_2022, Jan_2023, Feb_2023, Mar_2023,
                       Apr_2023, May_2023)
```

#### A quick snapshot for orientation and an idea of scale.
```{r}
str(all_trips)
ncol(all_trips)
nrow(all_trips)
```

### Checking for oddities that would require cleaning

#### Confirmation that there are only two labels for members.
```{r}
categories <- unique(all_trips$member_casual)
number_of_categories <- length(categories)
list(categories)
table(all_trips$member_casual)
```
There are no extraneous values to be removed, although there will be further
cleaning of nonsensical values.

#### These next steps split the datetime column into more human time, 
#### day, month, etc. 
Not entirely sure why format() could not extract the day of the week, but the weekdays() function worked perfectly.
```{r}
all_trips$date <- as.Date(all_trips$started_at)
all_trips$month <- format(as.Date(all_trips$date),"%m")
all_trips$day <- format(as.Date(all_trips$date),"%d")
all_trips$year <- format(as.Date(all_trips$date),"%Y")
all_trips$day_of_week <- weekdays(as.Date(all_trips$date))
```

#### Confirmation of the correct structure.
```{r}
table(all_trips$month)
table(all_trips$day)
table(all_trips$year)
table(all_trips$day_of_week)
```
12 months, 31 days, 2 years, and 7 days of the week, as expected.

#### Calculating the ride length and ensuring the correct format.
```{r}
all_trips$ride_length <- difftime(all_trips$ended_at, all_trips$started_at)
all_trips$ride_length <- as.numeric(as.character(all_trips$ride_length))
is.numeric(all_trips$ride_length)
```

#### Need to remove negative trip lengths and quality control checks

```{r}
all_trips_v2 <- subset(all_trips, all_trips$ride_length > 0 
                       & all_trips$start_station_name != "HQ QR")
```

Here is the other possibility that I would like to compare for speed. It should
be approximately the same, but this is syntax learning for my own benefit.
```{r}
## all_trips_v2 <- all_trips[!(all_trips$start_station_name == "HQ QR"
##                         | all_trips$ride_length<0),]
```

                            
#### Just a quick check for oddities
```{r}
summary(all_trips_v2$ride_length)
```
This summary shows a large maximum value, so it is best to check for outliers.

```{r}
ride_length_outlier_check <- all_trips_v2 %>%
  arrange(desc(ride_length))
ride_length_outlier_check[1:30, c("ride_id","ride_length", "member_casual")]
```
From this quick analysis, we see that there are many ride lengths that last on the order of weeks. It will be difficult (and probably erroneous) to classify these rides as outliers. Note: in the above script, all the rider types were casual, which may be significant. Because the number of these rides is so small, they are not huge disruptors of our data. However, this information could be useful in tracking lost bikes.

## Summary Statistics, Analysis, and Visualizations

#### Basic Overview: Mean, Median, Max, Min (In seconds)
```{r}
mean(all_trips_v2$ride_length)
median(all_trips_v2$ride_length)
max(all_trips_v2$ride_length)
min(all_trips_v2$ride_length)
sd(all_trips_v2$ride_length)
```

#### Summary Statistics, Separated by Rider Type
```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = length)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = mean)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = median)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = max)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = min)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = sd)
```

#### Number of Rides by Rider Type and Day of the Week (requested)
```{r}
## Number of rides by rider type and day of the week
all_trips_v2 %>%
  mutate(weekday = wday(started_at, label=TRUE)) %>%
  group_by(member_casual, weekday) %>%
  summarise(number_of_rides = n(), average_duration = mean(ride_length)) %>%
  arrange(member_casual, weekday)
```
```{r}
all_trips_v2 %>%
  mutate(weekday = wday(started_at, label=TRUE)) %>%
  group_by(member_casual, weekday) %>%
  summarise(number_of_rides = n(), average_duration = mean(ride_length)) %>%
  arrange(member_casual, weekday) %>%
  ggplot(aes(x=weekday, y=number_of_rides, fill=member_casual))+
  geom_col(position = "dodge")

```

#### Ride Duration by Rider Type and Day of the Week
```{r}
all_trips_v2 %>%
  mutate(weekday = wday(started_at, label=TRUE)) %>%
  group_by(member_casual, weekday) %>%
  summarise(number_of_rides = n(), average_duration = mean(ride_length)) %>%
  arrange(member_casual, weekday) %>%
  ggplot(aes(x=weekday, y=average_duration, fill=member_casual))+
  geom_col(position = "dodge")
```

#### Distribution of Ride Lengths (working version)
```{r}
ggplot(data = all_trips_v2) +
  geom_bar(mapping = aes(x=ride_length, fill = member_casual))+
    facet_wrap(~member_casual) +
    xlim(0,5000) +
    ylim(0,2000)+
  labs(title = "Ride Length", subtitle = "Differences between Casual Riders and Members", x = "Ride Time (sec)", y = ("Number of Rides"))
```

This shows the difference in the ways that members and casual riders use the bikeshare services. The most interesting feature to note is the gap in Ride Time for members. Additionally the longer tail on the Ride Time curve for casual users (cut short here) shows that casual riders are more likely to take longer rides.

## Next, we want to evaluate where advertising has the most potential to covert
## casual riders to members. Below are plots that show the most traveled staions,
## as well as a breakdown into members and casual riders.

```{r}
## This code creates the necessary tibbles.
members_only <- all_trips_v2[!(all_trips_v2$member_casual=="casual"),]
casual_riders_only <- all_trips_v2[!(all_trips_v2$member_casual=="member"),]

most_common_stations <- all_trips_v2 %>%
  group_by(start_station_name) %>%
  summarise(n = n()) %>%
  arrange(desc(n))

most_common_stations_members <- members_only %>%
  group_by(start_station_name) %>%
  summarise(n = n()) %>%
  arrange(desc(n))

most_common_stations_casual <- casual_riders_only %>%
  group_by(start_station_name) %>%
  summarise(n = n()) %>%
  arrange(desc(n))
```



```{r}
ggplot(data = most_common_stations[1:20,]) +
  geom_col(mapping =aes(x= start_station_name, y = n), fill = "blue") +
  labs(title = "Stations with Largest Total Ridership", x= "Station", 
       y = "Total Rides") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
  
ggplot(data = most_common_stations_members[1:20,]) +
  geom_col(mapping =aes(x= start_station_name, y = n), fill = "orange") +
  labs(title = "Stations with Largest Member Ridership", x= "Station", 
       y = "Total Rides") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
  
ggplot(data = most_common_stations_casual[1:20,]) +
  geom_col(mapping =aes(x= start_station_name, y = n), fill = "purple") +
  labs(title = "Stations with Largest Casual Ridership", x= "Station", 
       y = "Total Rides") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

## Final Conclusions

The business task for this project was to identify how casual riders and members differed in their use of Cyclistic bike rentals. We identified differences in daily use, ride length, and which stations each user type frequents. The most-used stations by casual riders would be the best locations for on-site advertising to covert more casual riders to members.

### For further research/inquiry: 
* If we can acquire anonymized data to link ride IDs with individual users, we could    determine how many casual riders are frequent riders, but not members.

* Is there a difference in ride distance between casual riders and members? Does        traffic usually go point-to-point or out-and-back?

* Traffic flow-- can we allocate bikes more efficiently? Are there times when           potential customers want to rent bikes, but none are available?

#### While not part of the business question, I am interested in an aspect that 
#### could save the company a lot of money. I want to analyze "Bike Flow," which
#### I will define as how many bikes are lost or gained by each station.